{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 7 - Lab 1: Advanced Agent Workflows with MCP (Solution)\n",
    "\n",
    "**Objective:** Learn to structure complex prompts for AI agents using the Model Context Protocol (MCP) to improve reliability and clarity, and build a code refactoring agent that leverages this protocol.\n",
    "\n",
    "**Introduction:**\n",
    "This solution notebook provides the complete code and explanations for using the Model Context Protocol. It covers manual formatting, programmatic construction with the SDK, and seamless integration with LangChain agents via adapters.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-21 22:30:23,648 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=gpt-4o latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "import importlib\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        importlib.import_module(package)\n",
    "    except ImportError:\n",
    "        print(f\"{package} not found, installing...\")\n",
    "        import subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "\n",
    "install_if_missing('mcp')\n",
    "install_if_missing('langchain_mcp_adapters')\n",
    "\n",
    "from utils import setup_llm_client, get_completion\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp.server.fastmcp import FastMCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges - Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Manually Formatting an MCP Prompt\n",
    "\n",
    "**Explanation:**\n",
    "This first step demonstrates the core idea of MCP. We create a standard string, but we embed XML-like tags to give the LLM structural cues. The `<request>` tag contains the user's direct command, while the `<context>` tag groups together all the supporting information. Inside the context, `<code>` and `<instructions>` provide specific, distinct pieces of information for the agent to use. This separation helps the model differentiate between the task and the data it needs to perform the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sending Manually Formatted MCP Prompt ---\n",
      "```python\n",
      "def calculate_double_sum(a: int, b: int) -> int:\n",
      "    sum_ab = a + b\n",
      "    doubled_sum = sum_ab * 2\n",
      "    return doubled_sum\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "code_to_refactor = \"def my_func(a,b):\\n  x=a+b\\n  y=x*2\\n  return y\"\n",
    "\n",
    "# TODO: Create a prompt string that manually uses MCP tags.\n",
    "manual_mcp_prompt = f\"\"\"\n",
    "<request>Please refactor this code.</request>\n",
    "<context>\n",
    "  <code>\n",
    "    {code_to_refactor}\n",
    "  </code>\n",
    "  <instructions>\n",
    "    Make this function more readable and add Python type hints.\n",
    "  </instructions>\n",
    "</context>\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Sending Manually Formatted MCP Prompt ---\")\n",
    "response = get_completion(manual_mcp_prompt, client, model_name, api_provider)\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Using the MCP SDK to Build a Prompt\n",
    "\n",
    "**Explanation:**\n",
    "Programmatically building the request with the MCP SDK is far superior to manual string formatting because it eliminates the risk of syntax errors and makes the prompt construction more modular, readable, and maintainable.\n",
    "\n",
    "1.  We create `Code` and `Instructions` objects, which are specific types of context items.\n",
    "2.  We group them into a `Context` object.\n",
    "3.  We create the top-level `Request` object.\n",
    "4.  The `.render()` method handles the conversion of these Python objects into the correctly formatted XML string, ensuring syntactical correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Request' from 'mcp' (/Users/agaleana/repos/AG-AISOFTDEV/.venv/lib/python3.11/site-packages/mcp/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Corrected import statement for the 'mcp' package\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmcp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Request, Context, Code, Instructions\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# TODO: Use the MCP SDK to build the request programmatically.\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 1. Create Code and Instructions items\u001b[39;00m\n\u001b[32m      7\u001b[39m code_item = Code(content=code_to_refactor, language=\u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'Request' from 'mcp' (/Users/agaleana/repos/AG-AISOFTDEV/.venv/lib/python3.11/site-packages/mcp/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Corrected import statement for the 'mcp' package\n",
    "from mcp import Request, Context, Code, Instructions\n",
    "\n",
    "# TODO: Use the MCP SDK to build the request programmatically.\n",
    "\n",
    "# 1. Create Code and Instructions items\n",
    "code_item = Code(content=code_to_refactor, language=\"python\")\n",
    "instructions_item = Instructions(content=\"Make this function more readable and add Python type hints.\")\n",
    "\n",
    "# 2. Create the Context object\n",
    "context_obj = Context(items=[code_item, instructions_item])\n",
    "\n",
    "# 3. Create the final Request object\n",
    "mcp_request = Request(\n",
    "    content=\"Please refactor this code.\",\n",
    "    context=context_obj\n",
    ")\n",
    "\n",
    "# 4. Render the request to a string\n",
    "rendered_prompt = mcp_request.render()\n",
    "\n",
    "print(\"--- Programmatically Rendered MCP Prompt ---\")\n",
    "print(rendered_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Building a Context-Aware Refactoring Agent\n",
    "\n",
    "**Explanation:**\n",
    "This pattern of using context builders and an MCP template is incredibly powerful for building production-ready agents. It allows you to create a stable, predictable interface for your agent, where you can easily add or remove different types of context without having to rewrite messy prompt strings.\n",
    "\n",
    "1.  **Context Builders:** We define which types of context our agent can accept using `CodeContextBuilder` and `InstructionsContextBuilder`. These builders know how to find the relevant data from the input dictionary.\n",
    "2.  **`McpChatPromptTemplate`:** This special prompt template is the core of the adapter. It takes our context builders and a request template. When the chain is invoked, it automatically uses the builders to find and format the context, then injects it into the final prompt sent to the LLM.\n",
    "3.  **Invocation:** The input to the `.invoke()` call is a simple dictionary. The keys (`code`, `instructions`, `user_request`) match the context builders and the template variables, allowing the adapter to correctly assemble the final, complex MCP prompt behind the scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters import McpChatPromptTemplate\n",
    "from langchain_mcp_adapters.context_builders import CodeContextBuilder, InstructionsContextBuilder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=model_name)\n",
    "\n",
    "# 1. Create a list of context builders\n",
    "context_builders = [\n",
    "    CodeContextBuilder(variable_name=\"code\", language=\"python\"),\n",
    "    InstructionsContextBuilder(variable_name=\"instructions\"),\n",
    "]\n",
    "\n",
    "# 2. Create the McpChatPromptTemplate\n",
    "mcp_prompt_template = McpChatPromptTemplate(\n",
    "    context_builders=context_builders,\n",
    "    request_template=\"{user_request}\",\n",
    ")\n",
    "\n",
    "# 3. Create the LangChain agent chain\n",
    "refactoring_agent = mcp_prompt_template | llm | StrOutputParser()\n",
    "\n",
    "# 4. Invoke the agent with a dictionary of inputs\n",
    "refactoring_input = {\n",
    "    \"user_request\": \"Please refactor this code to be more Pythonic.\",\n",
    "    \"code\": \"def f(data):\\n  r = []\\n  for i in data:\\n    if i % 2 == 0:\\n      r.append(i*i)\\n  return r\",\n",
    "    \"instructions\": \"Use a list comprehension and add type hints.\"\n",
    "}\n",
    "\n",
    "print(\"--- Invoking MCP-powered Refactoring Agent ---\")\n",
    "refactored_code = refactoring_agent.invoke(refactoring_input)\n",
    "print(refactored_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Excellent work! You have learned how to use the Model Context Protocol to create structured, reliable prompts for your AI agents. You progressed from manually writing MCP-formatted strings to using the SDK for programmatic construction, and finally to using the LangChain adapter for seamless integration. This skill is crucial for building advanced agents that need to handle diverse and complex contextual information in a predictable way.\n",
    "\n",
    "> **Key Takeaway:** Structuring prompts with a clear protocol like MCP makes agents more reliable. It separates the user's *request* from the *context* the agent needs, reducing ambiguity and allowing you to build more predictable, production-ready AI systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
